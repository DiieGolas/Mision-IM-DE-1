# -*- coding: utf-8 -*-
"""Fix_stars_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dVsaFcIt3bqQClGMI9MwrZTj-XuceFEQ

# Script en Google Colab - Fix_stars_data

>Intelimétrica Test

Desarrollador:
* Diego Andrés Navarro Pérez

Fecha Inicio:
* 24 de enero del 2021
---
Instrucciones:

**Misión  IM-DE-1**

Bienvenido soldado, se te ha asignado la misión IM-DE-1 en el cuartel espacial Intelimétrica.

Un pirata-espacial burló nuestros sistemas de seguridad logrando infiltrarse en nuestros sistemas y ha dañado un archivo de vital importancia, ya que contiene la información recopilada a lo largo de los últimos 100 años de las estrellas de nuestro universo. Nuestros científicos necesitan esta información para poder encontrar nuevas fuentes de energía, ya que nuestro sol está muriendo.

Soldado, tu misión es escribir un script que lea el archivo infectado (starts_data.csv) y lo transforme en un archivo PSV (Pipe Separated Values) formateado correctamente para que nuestros científicos puedan leerlo en cualquier CSV/PSV parser.


Tu deber es que:
1. Cada valor deberá estar separada por el carácter ‘|’ (Pipe). Ej: (v_1|v_2|v_3)
2. Cada linea deberá tener el mismo numero de columnas.
3. Cada valor deberá tener el quotechar ‘”’(Doble comillas). Ej. Ej: (“v_1”|”v_2”|”v_3”)
4. El archivo deberá estar almacenado con un enconding de UTF-8

Soldado, contamos con tus habilidades para salvar los datos, cada segundo cuenta…

Al finalizar tu misión deberás enviarnos el script y el archivo PSV que obtuviste.

Te deseamos todo el éxito para lograr completar esta misión.

Liga para obtener el dataset dañado:

https://recruiting-datasets.s3.us-east-2.amazonaws.com/starts_data.csv

## Importando librerías
"""

# -*- coding: utf-8 -*-

import csv
#import sys
import os
import pandas as pd
#import numpy as np

"""## Ajustando el archivo .csv a .psv y limpiando/acomodando los datos"""

# Cargar el dataset starts_data.csv a Google colab
# Leer el archivo 'starts_data.csv' con reader() y 
# mostrar todos los registros, uno a uno:

with open('starts_data.csv') as csvarchivo:
  entrada = csv.reader(csvarchivo)
  #for row in entrada:
    #print(row)  # Cada línea se muestra como una lista de campos

#Convertimos los delimitadores de '~'s por ','s y creamos un archivo .psv

with open('starts_data.csv','r') as csvin, open('salida.psv', 'w') as psvout:
  csvin = csv.reader(csvin, delimiter='~')
  psvout = csv.writer(psvout, delimiter=',')

  for row in csvin:
    psvout.writerow(row)

#Convertimos los delimitadores de '\t's por ','s y creamos un archivo .psv

with open('salida.psv','r') as csvin, open('salida1.psv', 'w') as psvout:
  csvin = csv.reader(csvin, delimiter='\t')
  psvout = csv.writer(psvout, delimiter=',')

  for row in csvin:
    psvout.writerow(row)

#Convertimos los delimitadores de '°'s (caracter imposible) por ','s y creamos un archivo .psv
# ¡¡Esto se hace para preparar los datos y que estén parejos para añadir las comillas!!

with open('salida1.psv','r') as csvin, open('salida2.psv', 'w') as psvout:
  csvin = csv.reader(csvin, delimiter='°')
  psvout = csv.writer(psvout, delimiter=',')

  for row in csvin:
    psvout.writerow(row)

#Convertimos los delimitadores de ','s por '|'s y creamos un archivo .psv
#Este paso elimina las comillas agregadas al inicio y al final de cada fila

with open('salida2.psv','r') as csvin, open('salida3.psv', 'w') as psvout:
  csvin = csv.reader(csvin, delimiter=',')
  psvout = csv.writer(psvout, delimiter='|')

  for row in csvin:
    psvout.writerow(row)

#Convertimos los delimitadores de '|'s por '|'s y creamos el archivo .psv y agregamos las comillas dobles a todos los valores
#Esto es para caa valor en cada fila

with open('salida3.psv','r') as csvin, open('salida4.psv', 'w') as psvout:
  csvin = csv.reader(csvin, delimiter=',')
  psvout = csv.writer(psvout, delimiter='|', quotechar='"', quoting=csv.QUOTE_ALL)

  for row in csvin:
    psvout.writerow(row)

#Eliminar la primer y última fila del archivo con información dañada/agregada e innecesaria

f = open('salida4.psv', 'r')
lineas = f.readlines()
#print(lineas)
f.close()
lineas.pop(0)
lineas.pop(len(lineas)-1)
f = open('stars_data_fixed.psv', 'w', encoding='utf-8') #Codificar el archivo a UTF-8
for linea in lineas:
  f.write(linea)
f.close()

os.remove('salida.psv')
os.remove('salida1.psv')
os.remove('salida2.psv')
os.remove('salida3.psv')
os.remove('salida4.psv')

"""## Leyendo/obteniendo los datos del dataset arreglado

Transformado a .csv y cargado a Google colab
"""

#Cargamos los datos de entrada
stars_data = pd.read_csv("stars_data_fixed.csv")
stars_data.head(10) #Los espacios vacíos quedan marcados como 'NaN', mismos que pueden ignorarse, editarse o no tomarse en cuenta con un dataset nuevo que elimine filas incompletas

#Veamos cuantas dimensiones y registros contiene
stars_data.shape #Contiene 119615 filas y 37 columnas

# Ahora veamos algunas estadísticas de nuestros datos
stars_data.describe() #Estadística entre los valores encontrados en nuestro dataset por cada categoría/columna